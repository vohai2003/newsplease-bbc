{"authors": ["Nalini Sivathasan, Patrick Clahane & Debula Kemoli", "www.facebook.com"], "date_download": "2025-04-26 04:34:06", "date_modify": "2025-04-26 04:34:06", "date_publish": "2025-03-03 00:46:09", "description": "Young women in Kenya tell the BBC they have used TikTok to sell sexual content since they were teenagers.", "filename": "news_articles_cedl8eyy4pjo_1745642046.html", "image_url": "https://ichef.bbci.co.uk/ace/branded_news/1200/cpsprodpb/d00b/live/020d8900-f5b2-11ef-8c03-7dfdbeeb2526.png", "language": "en", "localpath": "C:\\Users\\vopha/news-please-repo//data/2025/04/26/bbc.co.uk/news_articles_cedl8eyy4pjo_1745642046.html", "title": "TikTok profiting from sexual livestreams in Kenya involving children, BBC told", "title_page": "TikTok profiting from sexual livestreams in Kenya involving children, BBC told - BBC News", "title_rss": "NULL", "source_domain": "bbc.co.uk", "maintext": "TikTok is profiting from sexual livestreams performed by teens as young as 15, the BBC has been told.\nWe spoke to three women in Kenya who said they began this activity as teenagers. They told us they used TikTok to openly advertise and negotiate payment for more explicit content that would be sent via other messaging platforms.\nTikTok bans solicitation but the company knows it takes place, moderators have told the BBC. TikTok takes a cut of about 70% from all livestream transactions, we have previously found.\nTikTok told the BBC it has \"zero tolerance for exploitation\".\nLivestreams from Kenya are popular on TikTok - each night over the course of a week, we found up to a dozen in which women performers danced suggestively, watched by hundreds of people around the world.\nWarning: Contains details of a sexual nature\nIt's two o'clock in the morning in Nairobi, and the TikTok Lives are in full flow.\nMusic blasts, and users chat over each other, as a woman turns her camera on to twerk or pose provocatively. Emoji \"gifts\" then fill the screen.\n\"Inbox me for kinembe guys. Tap, tap,\" the performers say on repeat. \"Tap, tap,\" is a phrase commonly used on TikTok, calling for viewers to \"like\" a livestream.\n\"Kinembe\" is Swahili for \"clitoris\". \"Inbox me\" instructs the viewer to send a private message over TikTok with a more explicit bespoke request - such as to watch the performer masturbating, stripping or performing sexual activities with other women.\nIn some of the livestreams we watched, coded sexual slang was used to advertise sexual services.\nThe emoji gifts act as payment for the TikTok livestreams and - because TikTok removes any obvious sexual acts and nudity - also the more explicit content sent later on other platforms. The gifts can be converted into cash.\n\"It's not in TikTok's interest to clamp down on soliciting of sex - the more people give gifts on a livestream… [the] more revenue for TikTok,\" says a Kenyan former moderator we are calling Jo - one of more than 40,000 moderators TikTok says it employs globally, external.\nWe discovered that TikTok is still taking about a 70% cut from livestream gifts. The company denied it took such a large commission after we established the same cut in a 2022 investigation.\nTikTok has long been aware of child exploitation in its livestreams - having run its own internal investigation in 2022 - but ignored the issue because it \"profited significantly\" from them, according to the claims of a lawsuit brought by the US state of Utah last year, external.\nTikTok responded that the lawsuit - which is ongoing - ignored the \"proactive measures\" it had made to improve safety.\nKenya is a hotspot for this abuse, says the charity ChildFund Kenya, compounded by a young demographic and widespread internet usage. The African continent as a whole also has poor online moderation compared to Western countries, the charity added.\nJo, who worked for Teleperformance - contracted by TikTok to provide content moderation - says moderators are given a reference guide of banned sexual words or actions. But this guide is restrictive, says Jo, and does not take into account slang or other provocative gestures.\n\"You can see by the way they are posing, with the camera on their cleavage and thighs [for example], that they are soliciting sex. They may not say anything, but you can see they are signposting to their [other platform] account, but there's nothing I can do.\"\nAnother content moderator for Teleperformance, who we are calling Kelvin, says moderation is also limited by TikTok's increasing reliance on artificial intelligence (AI), which he says is not sensitive enough to pick up on local sexual slang.\nJo and Kelvin are among seven current and former content moderators working on TikTok content who told us their concerns. Jo says about 80% of livestreams flagged in content moderators' feeds were sexual, or advertising sexual services, and TikTok is aware of the scale of the issue.\nChildFund Kenya and other charities have told the BBC that children as young as nine are taking part in these activities.\nWe have spoken to teenage girls and young women who say they are spending up to six or seven hours a night on the activity and making on average £30 a day - enough to pay for a week's food and transport.\n\"I sell myself on TikTok. I dance naked. I do that because that's where I can earn money to support myself,\" says a 17-year-old we are calling Esther. She lives in a poor Nairobi neighbourhood, where 3,000 residents share toilet facilities. She says the money helps her buy food for her child, and support her mother who has been struggling to pay the rent since Esther's father died.\nShe says she was 15 years old when she was introduced to TikTok Lives by a friend, who helped her bypass the age restrictions - only over-18s can use a Live. Users also need at least 1,000 followers to go live.\nSo TikTok users with a big following can act as digital pimps - hosting the livestreams selling sexual content. Some of them have back-up accounts, indicating they have been banned or suspended by TikTok in the past.\nThey appear to know how to evade detection by TikTok's content moderators, while generating the right amount of sexual teasing to pique customers' interest.\n\"When you're dancing, move away from the camera, otherwise you'll get blocked,\" shouts a pimp to a woman twerking on screen.\nIn return for being hosted, the women give pimps a cut of their earnings.\nThe relationship can quickly turn exploitative, says Esther. She says her digital pimp knew she was under 18, and \"he likes using young girls\".\nHe put pressure on her to earn more - meaning she needed to livestream more frequently - and took a larger cut of her earnings than she expected, she says.\n\"So if an emoji is sent which is 35,000ksh (£213), he takes 20,000ksh (£121) and you only get 15,000ksh (£91).\"\nWorking for him was like being in \"handcuffs\" she says. \"You are the one hurting because he gets the biggest share and yet it is you who has been used.\"\n\"Sophie\", not her real name, who says she was also 15 when she started livestreaming on TikTok, says she got requests from men in Europe for services on third-party platforms, including from one a German user who would demand that she caress her breasts and genitals for money.\nNow 18, she regrets her online sex work. Some of the videos she sent to users via other platforms were then uploaded to social media without her consent, she says.\nHer neighbours found out, and warned other young people not to associate with her, she told the BBC.\n\"They brand me as a lost sheep, and young people are told that I'll mislead them. I am lonely most of the time.\"\nSome of the girls and women we spoke to said they had also been paid to meet TikTok users for sex in person, or had been pressured into having sex with their pimps.\nTikTok is keen to establish itself in African markets, but is not employing enough staff to effectively monitor content, the content moderators in Kenya told us.\nKenya's government has shown signs of acknowledging the issue - in 2023, President William Ruto held a meeting with TikTok's CEO Shou Zi Chew to call for better content moderation on the platform, external. The government said the company had agreed to tighter regulation, with a TikTok office in Kenya to help co-ordinate operations.\nBut the moderators we spoke to said, more than 18 months later, neither had happened.\nTeleperformance replied that its moderators \"work diligently to tag and flag user-generated content based on community standards and client guidelines\" and that its clients' systems are not set up to allow Teleperformance to remove offending material or report it to law enforcement authorities.\nA spokesperson for TikTok told the BBC:\n\"TikTok has zero tolerance for exploitation. We enforce strict safety policies, including robust Live content rules, moderation in 70 languages, including Swahili, and we partner with local experts and creators, including our Sub-Saharan Africa Safety Advisory Council to continually strengthen our approach.\"", "url": "https://www.bbc.co.uk/news/articles/cedl8eyy4pjo"}